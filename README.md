As a researcher in neuroinformatics, I manage bio-data analysis workflows on a daily basis, developing ML pipelines (clustering, classification, regression, etc) with the goal of creating tools capable of predicting disease progression or classifying patients into pathological groups, and used as second opinion systems for healthcare professionals. I daily use Python (scikit-learn, SHAP, pandas, NumPy, Scipy, etc.) for the development of ML and data analysis pipelines, Shell scripting (Linux environment), R, Matlab, Wordpress, Git-Hub for development of services and web portals aimed to: (i) help scientists do high-throughput  research, (ii) provide clinical professionals automated diagnostic biomarkers of diseases for single case analysis and individual patient characterization, (iii) provide secure data storage and data archiving. I daily perform bio-data analysis through different analysis tools (SPM, FSL, Matlab, Python, etc). As a member of the Neuroinformatics Unit at FBF, I also manage a server (Linux-based environment) equipped with a High-Performance Computing (HPC) center featuring 500+ CPUs, 4+ TB RAM, 1000+ TB storage, and 8 A100 GPUs with 40 GB each. The computing cluster is managed within a virtual environment and controlled by the Sun Grid Engine scheduler. The HPC is equipped with popular computing environments (Docker, Singularity, Python, R). 
